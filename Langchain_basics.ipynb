{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288ce9a8",
   "metadata": {},
   "source": [
    "# LangChain Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "002d92f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing the required libraries\n",
    "!pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff28727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip - installs the packages in the base environment\n",
    "# pip - installs the packages in the virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf2f431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.0.238\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://www.github.com/hwchase17/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: C:\\Users\\Ryan\\anaconda3\\envs\\llm_env\\Lib\\site-packages\n",
      "Requires: aiohttp, dataclasses-json, langsmith, numexpr, numpy, openapi-schema-pydantic, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d14256a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upgrading langchain\n",
    "!pip install langchain --upgrade -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4407a3a",
   "metadata": {},
   "source": [
    "#### Python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9420415",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# loading the API Keys (OpenAI, Pinecone) from .env\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# os.environ.get('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29231e2",
   "metadata": {},
   "source": [
    "### LLM Models (Wrappers): GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d37cc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.7, 'max_tokens': 512, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=512)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d355809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Quantum mechanics is a branch of physics that explains the behavior of matter and energy on the atomic and subatomic level.\n"
     ]
    }
   ],
   "source": [
    "output = llm('explain quantum mechanics in one sentence')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e29c5e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(llm.get_num_tokens('explain quantum mechanics in one sentence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d00248e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.generate(['... is the capital of France.', \n",
    "                   'What is the formula for the area of a circle?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b98fd88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Generation(text='\\n\\nParis', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nThe formula for the area of a circle is A = πr², where r is the radius of the circle and π is the mathematical constant approximately equal to 3.14.', generation_info={'finish_reason': 'stop', 'logprobs': None})]]\n"
     ]
    }
   ],
   "source": [
    "print(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0725e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Paris\n"
     ]
    }
   ],
   "source": [
    "print(output.generations[0][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7703b86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "779b3a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.generate(['Write an orignal tagline for a burger restaurant'] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d3cdfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Taste the Burgers of Your Dreams!\"\n",
      "\n",
      "\"Sink your teeth into something delicious - try a burger from [restaurant name] today!\"\n",
      "\n",
      "\"Beefed Up Burgers: The Taste That Satisfies!\""
     ]
    }
   ],
   "source": [
    "for o in output.generations:\n",
    "    print(o[0].text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20ee709",
   "metadata": {},
   "source": [
    "### ChatModels: GPT-3.5-Turbo and GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "054eadaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9bdecaa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5, max_tokens=1024)\n",
    "messages = [\n",
    "    SystemMessage(content='You are a physicist and respond only in German.'),\n",
    "    HumanMessage(content='explain quantum mechanics in one sentence')\n",
    "]\n",
    "output = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "761e06dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantenmechanik beschreibt das Verhalten von Teilchen auf atomarer und subatomarer Ebene durch probabilistische Wellenfunktionen.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ad29b",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a31ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "612ed8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['virus', 'language'] output_parser=None partial_variables={} template='You are an experienced virologist.\\nWrite a few sentences about the following {virus} in {language}.' template_format='f-string' validate_template=True\n"
     ]
    }
   ],
   "source": [
    "template = '''You are an experienced virologist.\n",
    "Write a few sentences about the following {virus} in {language}.'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['virus', 'language'],\n",
    "    template=template\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b28accc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "La malaria est une maladie infectieuse causée par des parasites du genre Plasmodium, qui sont transmis à l'être humain par des moustiques infectés. Les symptômes de la malaria comprennent des frissons, de la fièvre, des maux de tête, des douleurs musculaires et des vomissements. La malaria peut être grave et potentiellement mortelle si elle n'est pas traitée rapidement et correctement. Il est important pour les médecins et les virologistes de comprendre le cycle de vie et les caractéristiques des parasites Plasmodium afin de mieux contrôler et traiter la maladie.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7)\n",
    "output = llm(prompt.format(virus='Malaria', language='French'))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025d9b84",
   "metadata": {},
   "source": [
    "### Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd1e5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5)\n",
    "template = '''You are an experienced virologist.\n",
    "Write a few sentences about the following {virus} in {language}.'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['virus', 'language'],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "output = chain.run({'virus': 'HSV', 'language': 'french'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be42818a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le HSV, ou virus de l'herpès simplex, est un virus à ADN de la famille des Herpesviridae. Il existe deux types de HSV : le HSV-1, principalement responsable des infections buccales et labiales, et le HSV-2, qui est généralement associé aux infections génitales. Ces virus peuvent se transmettre par contact direct avec une personne infectée ou par le biais de fluides corporels. Les symptômes courants comprennent des lésions cutanées douloureuses, des démangeaisons et des brûlures. Bien que les infections à HSV ne puissent pas être guéries, des médicaments antiviraux peuvent aider à réduire les symptômes et à prévenir les récidives.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f283cc13",
   "metadata": {},
   "source": [
    "### Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d68115d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "def softmax(x):\n",
      "    \"\"\"\n",
      "    Compute softmax values for each sets of scores in x.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x : list of numbers, numpy array\n",
      "        Input scores\n",
      " \n",
      "    Returns\n",
      "    -------\n",
      "    output : numpy array\n",
      "        Softmax scores\n",
      "    \n",
      "    \"\"\"\n",
      "    # Use exp() to calculate softmax\n",
      "    exps = np.exp(x)\n",
      "    # Calculate the sum of the exponentials \n",
      "    sum_exps = np.sum(exps)\n",
      "    # Calculate softmax\n",
      "    output = exps / sum_exps\n",
      "    return output\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe given function is a Python function named `softmax`. It computes the softmax values for a list of scores provided as input. The function takes in an input variable `x`, which is expected to be a list of numbers or a numpy array.\n",
      "\n",
      "The softmax function is commonly used in machine learning and deep learning models to convert a vector of real values into a probability distribution. It is calculated by exponentiating each element of the input vector and then normalizing the resulting values by dividing them by the sum of all exponentiated elements.\n",
      "\n",
      "Within the given function, the input scores `x` are exponentiated using the numpy function `np.exp()`, which returns an array of equally-sized exponentiated values.\n",
      "\n",
      "Next, the sum of all exponentiated values is calculated using the numpy function `np.sum()`.\n",
      "\n",
      "Finally, the softmax values are computed by dividing each exponentiated value by the sum of all exponentiated values. The result is an array of probabilities representing the softmax distribution.\n",
      "\n",
      "The function returns the computed softmax scores as a numpy array named `output`.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "llm1 = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=1024)\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=['concept'],\n",
    "    template='''You are an experienced scientist and Python programmer.\n",
    "    Write a function that implements the concept of {concept}.'''\n",
    ")\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt1)\n",
    "\n",
    "\n",
    "llm2 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1.2)\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=['function'],\n",
    "    template='Given the Python function {function}, describe it as detailed as possible.'\n",
    ")\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt2)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "output = overall_chain.run('softmax')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a9c39",
   "metadata": {},
   "source": [
    "### LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "631fd9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool  \n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "115e2fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I need to use the Python REPL to calculate this\n",
      "Action: Python_REPL\n",
      "Action Input: print(5.1 ** 7.3)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m146306.05007233328\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 146306.05007233328\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'146306.05007233328'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "agent_executor = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")\n",
    "# agent_executor.run('Calculate the square root of the factorial of 20 \\\n",
    "# and display it with 4 decimal points')\n",
    "\n",
    "agent_executor.run('what is the answer to 5.1 ** 7.3?')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0af1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
